{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.path import Path\n",
    "import seaborn as sns\n",
    "\n",
    "# Set this to True if you want to use Latex. \n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "def draw_error_band(ax, x, y, err, **kwargs):\n",
    "    \"\"\"\n",
    "    Draw an error band on a matplotlib Axes object. Taken from: https://matplotlib.org/stable/gallery/lines_bars_and_markers/curve_error_band.html\n",
    "\n",
    "    Parameters:\n",
    "    - ax (matplotlib.axes.Axes): The Axes object to draw the error band on.\n",
    "    - x (array-like): The x-coordinates of the data points.\n",
    "    - y (array-like): The y-coordinates of the data points.\n",
    "    - err (float): The error magnitude to determine the width of the error band.\n",
    "    - **kwargs: Additional keyword arguments to be passed to the PathPatch constructor.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    dx = np.concatenate([[x[1] - x[0]], x[2:] - x[:-2], [x[-1] - x[-2]]])\n",
    "    dy = np.concatenate([[y[1] - y[0]], y[2:] - y[:-2], [y[-1] - y[-2]]])\n",
    "    l = np.hypot(dx, dy)\n",
    "    nx = dy / l\n",
    "    ny = -dx / l\n",
    "\n",
    "    # end points of errors\n",
    "    xp = x + nx * err\n",
    "    yp = y + ny * err\n",
    "    xn = x - nx * err\n",
    "    yn = y - ny * err\n",
    "\n",
    "    vertices = np.block([[xp, xn[::-1]], [yp, yn[::-1]]]).T\n",
    "    codes = np.full(len(vertices), Path.LINETO)\n",
    "    codes[0] = codes[len(xp)] = Path.MOVETO\n",
    "    path = Path(vertices, codes)\n",
    "    ax.add_patch(PathPatch(path, **kwargs))\n",
    "\n",
    "def plot_key(df, key, markers, colors, ax, show_legend=True, x_scale=1):\n",
    "    \"\"\"\n",
    "    Plot a key from a DataFrame on a given axis.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame containing the data.\n",
    "    - key (str): The key/column name to plot.\n",
    "    - markers (list): List of marker styles for each plot.\n",
    "    - colors (list): List of colors for each plot.\n",
    "    - ax (matplotlib.axes.Axes): The axis to plot on.\n",
    "    - show_legend (bool): Whether to show the legend. Default is True.\n",
    "    - x_scale (int): Scaling factor for the x-axis. Default is 1. This is useful to align the values if multiple x-axis are used\n",
    "\n",
    "    Returns:\n",
    "    - legend_entries (list): List of legend entries for each plot.\n",
    "    \"\"\"\n",
    "    ysmall = df[(df[\"model\"] == \"small\") & (df[\"batch\"] == True)][key][\"mean\"].values[0]\n",
    "    ysmall_std = df[(df[\"model\"] == \"small\") & (df[\"batch\"] == True)][key][\"std\"].values[0]\n",
    "    ybig = df[(df[\"model\"] == \"big\") & (df[\"batch\"] == True)][key][\"mean\"].values[0]\n",
    "    ybig_std = df[(df[\"model\"] == \"big\") & (df[\"batch\"] == True)][key][\"std\"].values[0]\n",
    "\n",
    "    if ysmall_std > 0 and ybig_std > 0:\n",
    "        ax.errorbar([0, 1*x_scale], [ysmall, ybig], yerr=[ysmall_std, ybig_std], c=\"k\", fmt='x')\n",
    "    else:\n",
    "        ax.scatter([0, 1*x_scale], [ysmall, ybig], c=\"k\", marker='x')\n",
    "\n",
    "    plot_number = 0\n",
    "    legend_entries = []\n",
    "\n",
    "    ymax = ybig_std + ybig\n",
    "    ymin = ysmall - ysmall_std\n",
    "    for c in df[\"calibration\"].dropna().unique():\n",
    "        for tm in df[\"train_method\"].dropna().unique():\n",
    "            x = df[(df[\"model\"] == \"RE\") & (df[\"batch\"] == True) & (df[\"train_method\"] == tm) & (df[\"calibration\"] == c)][\"p\"]\n",
    "            y = df[(df[\"model\"] == \"RE\") & (df[\"batch\"] == True) & (df[\"train_method\"] == tm) & (df[\"calibration\"] == c)][key][\"mean\"]\n",
    "            yerr = df[(df[\"model\"] == \"RE\") & (df[\"batch\"] == True) & (df[\"train_method\"] == tm) & (df[\"calibration\"] == c)][key][\"std\"]\n",
    "\n",
    "            x = x * x_scale\n",
    "            legend_entries.append(f\"{tm} {'no calibration' if not c else 'calibrated'}\")\n",
    "\n",
    "            yerr = np.array(yerr)\n",
    "            y = np.array(y)\n",
    "            for i in range(len(y)):\n",
    "                if i == 0 and np.isnan(y[i]):\n",
    "                    tmp = [yi for yi in y if not np.isnan(yi)]\n",
    "                    y[i] = np.amin(tmp) if len(tmp) > 0 else 0\n",
    "                elif i > 0 and np.isnan(y[i]):\n",
    "                    y[i] = y[i-1]\n",
    "\n",
    "                if i == 0 and np.isnan(yerr[i]):\n",
    "                    yerr[i] = 0\n",
    "                elif i > 0 and np.isnan(yerr[i]):\n",
    "                    yerr[i] = yerr[i-1]\n",
    "            yerr = np.array(yerr)\n",
    "            y = np.array(y)\n",
    "\n",
    "            if show_legend:\n",
    "                ax.plot(x, y, color=colors[plot_number], marker=markers[plot_number], label=f\"{tm} {'no calibration' if not c else 'calibrated'}\", markersize=4)\n",
    "            else:\n",
    "                ax.plot(x, y, color=colors[plot_number], marker=markers[plot_number], markersize=4)\n",
    "\n",
    "            if key == \"p_per_batch\":\n",
    "                yerr = df[(df[\"model\"] == \"RE\") & (df[\"batch\"] == True) & (df[\"train_method\"] == tm) & (df[\"calibration\"] == c)][\"p_per_batch_std\"][\"mean\"]\n",
    "\n",
    "            ax.fill_between(x, y - yerr, y + yerr, color=colors[plot_number], alpha=0.2)\n",
    "            ymax = max(ymax, np.amax(y+yerr))\n",
    "            ymin = min(ymin, np.amin(y-yerr))\n",
    "\n",
    "            plot_number = plot_number+1 if plot_number+1 < len(colors) else 0\n",
    "\n",
    "    if not (np.isnan(ymin) or np.isinf(ymin) or np.isnan(ymax) or np.isinf(ymax)):\n",
    "        ax.set_ylim([ymin-ymin*0.01, ymax+ymax*0.01])\n",
    "    return legend_entries\n",
    "\n",
    "def merge_lists(x):\n",
    "    \"\"\"\n",
    "    Simple helper function. Merge a list of lists into a single list.\n",
    "\n",
    "    Args:\n",
    "        x (list): A list of lists.\n",
    "\n",
    "    Returns:\n",
    "        list: A single merged list containing all elements from the input lists.\n",
    "    \"\"\"\n",
    "    merged_list = []\n",
    "    for sublist in x:\n",
    "        merged_list.extend(sublist)\n",
    "    return merged_list\n",
    "\n",
    "def plot_distribution(dff, ax, cal_unique, train_unique, markers, colors):\n",
    "    \"\"\"\n",
    "    Plot the distribution of the usage of the big model for various training methods. \n",
    "\n",
    "    Args:\n",
    "        dff (DataFrame): The input DataFrame containing the data.\n",
    "        ax (Axes): The matplotlib Axes object to plot on.\n",
    "        cal_unique (list): List of unique calibration values in dff. Usually this is just [True, False]\n",
    "        train_unique (list): List of unique training methods. Usually, this is just [\"virtual-labels\", \"confidence\"]\n",
    "        markers (list): List of markers for each plot.\n",
    "        colors (list): List of colors for each plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    plot_number = 0\n",
    "\n",
    "    for c in cal_unique:\n",
    "        for tm in train_unique:\n",
    "            ps = dff[(dff[\"model\"] == \"RE\") & (dff[\"batch\"] == True) & (dff[\"train_method\"] == tm) & (dff[\"calibration\"] == c)][\"p\"]\n",
    "            ymean = []\n",
    "            all_y = []\n",
    "            all_x = []\n",
    "            for pi in ps:\n",
    "                y = dff[(dff[\"model\"] == \"RE\") & (dff[\"batch\"] == True) & (dff[\"train_method\"] == tm) & (dff[\"calibration\"] == c) & (dff[\"p\"] == pi)][\"p_per_batch\"].values[0]\n",
    "                x = [pi for _ in range(len(y))]\n",
    "                all_x.extend(x)\n",
    "                all_y.extend(y)\n",
    "                ymean.append(np.mean(y))\n",
    "            \n",
    "            if len(all_x) > 10_000:\n",
    "                idx = np.random.choice(range(len(all_x)), size=10_000, replace=False)\n",
    "            else:\n",
    "                idx = range(len(all_x))\n",
    "\n",
    "            all_x = np.array(all_x)[idx]\n",
    "            all_y = np.array(all_y)[idx]\n",
    "            sns.stripplot(x=all_x, y=all_y, jitter=0.2, size=1,ax=ax, color=colors[plot_number])\n",
    "            ax.plot(ax.get_xticks(), ymean, c = colors[plot_number], marker=markers[plot_number], zorder=2,  markersize=4)\n",
    "            plot_number = plot_number+1 if plot_number+1 < len(colors) else 0\n",
    "        \n",
    "    x = ax.get_xticks()\n",
    "    y = [xi / max(x) for xi in x]\n",
    "    ax.plot(x,y, c=\"k\", linestyle=\"--\", alpha=0.5, zorder=3)\n",
    "\n",
    "def read_json(json_path):\n",
    "    \"\"\"\n",
    "    Reads a JSON file containing metrics data and returns a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    json_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    df (pandas.DataFrame): The DataFrame containing the metrics data.\n",
    "    keys (list): The list of keys used for aggregation.\n",
    "\n",
    "    \"\"\"\n",
    "    metrics = json.load(open(json_path,\"r\"))\n",
    "\n",
    "    df_metrics = [{\n",
    "        \"model\":m[\"model\"],\n",
    "        \"rejector\":m[\"rejector\"],\n",
    "        \"run\":m[\"run\"],\n",
    "        \"batch\":m[\"batch\"],\n",
    "        \"p\":m[\"p\"],\n",
    "        \"p_per_batch\":m[\"p_per_batch\"],\n",
    "        \"train_method\":m[\"train_method\"],\n",
    "        \"calibration\":m[\"calibration\"],\n",
    "        \"f1 macro\":m[\"f1 macro\"],\n",
    "        \"f1 micro\":m[\"f1 micro\"],\n",
    "        \"accuracy\":m[\"accuracy\"],\n",
    "        \"time\":np.mean(m[\"time\"]),\n",
    "        \"power\":np.mean(m[\"power_per_batch\"]),\n",
    "        \"poweravg\":np.mean(m[\"poweravg_per_batch\"])\n",
    "    } for m in metrics]\n",
    "\n",
    "    df = pd.DataFrame(df_metrics)\n",
    "    \n",
    "    df[\"p_per_batch_std\"] = df[\"p_per_batch\"].apply(lambda x: np.std(x))\n",
    "    df[\"p_per_batch\"] = df[\"p_per_batch\"].apply(lambda x: np.mean(x))\n",
    "\n",
    "    def batch_failed(row):\n",
    "        p = row[\"p\"]\n",
    "        return 1 if row[\"p_per_batch\"] > p else 0\n",
    "\n",
    "    df[\"failed_batches\"] = df.apply(batch_failed, axis=1)\n",
    "    agg = {\n",
    "        \"time\":['mean','std'],\n",
    "        \"f1 macro\":['mean','std'],\n",
    "        \"f1 micro\":['mean','std'],\n",
    "        \"accuracy\":['mean','std'],\n",
    "        \"power\":['mean','std'],\n",
    "        \"poweravg\":['mean','std'],\n",
    "        \"p_per_batch\":['mean','std'],\n",
    "        \"p_per_batch_std\":['mean','std'],\n",
    "        \"failed_batches\":['mean','std'],\n",
    "    }\n",
    "\n",
    "    df = df.groupby([\"model\", \"rejector\", \"p\", \"batch\", \"train_method\", \"calibration\"], dropna=False).agg(agg)\n",
    "    df.reset_index(inplace=True)\n",
    "    df[\"power\"] = df[\"power\"] / 1000\n",
    "    df[\"poweravg\"] = df[\"poweravg\"] / 1000\n",
    "    return df, agg.keys()\n",
    "\n",
    "def read_grouped(json_path):\n",
    "    \"\"\"\n",
    "    Read and process a JSON file containing metrics data and returns a dataframe containing the usage of the big model per batch.\n",
    "\n",
    "    Parameters:\n",
    "    json_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the processed metrics data, i.e. a dataframe containing the usage of the big model per batch.\n",
    "    \"\"\"\n",
    "    metrics = json.load(open(json_path,\"r\"))\n",
    "\n",
    "    df = pd.DataFrame(metrics)\n",
    "    dff = df.groupby([\"model\", \"rejector\", \"p\", \"batch\", \"train_method\", \"calibration\"]).agg({\n",
    "        'p_per_batch': merge_lists,\n",
    "    }).reset_index()\n",
    "\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files for plotting \n",
    "all_files = [os.path.join(\"rf\", f) for f in os.listdir(\"rf\") if os.path.join(\"rf\", f) and f.endswith(\".json\") ] + [os.path.join(\"dt3\", f) for f in os.listdir(\"dt3\") if os.path.join(\"dt3\", f) and f.endswith(\".json\") ] + [\"cifar100.json\", \"imagenet.json\"]\n",
    "\n",
    "# Generate individual plots for accuracy / time / power consumption. These plot the raw data and are not used in the paper directly.\n",
    "for p in all_files:\n",
    "    df, agg_keys = read_json(p)\n",
    "    name = p.split(\".\")[0]\n",
    "\n",
    "    colors = ['#66c2a5','#fc8d62','#8da0cb','#e78ac3']\n",
    "    markers = [\"s\", \"*\", \"x\", \"D\"]\n",
    "\n",
    "    for m in df[\"rejector\"].dropna().unique():\n",
    "        dff = df[ (df[\"rejector\"] == m) | (df[\"rejector\"].isna()) ]\n",
    "        for key in [\"accuracy\", \"time\", \"power\"]:\n",
    "            plot_key(dff, key, markers, colors, plt.gca(), show_legend = True)\n",
    "            if key == \"accuracy\":\n",
    "                plt.title(f\"Test accuracy on {name}\")\n",
    "                plt.ylabel(f\"Accuracy\")\n",
    "            elif key == \"poweravg\" or key == \"power\":\n",
    "                plt.title(f\"Average power consumption per batch on {name}\")\n",
    "                plt.ylabel(f\"Watt\")\n",
    "            else:    \n",
    "                plt.title(f\"{key} on {name}\")\n",
    "            plt.xlabel(\"p\")\n",
    "            plt.legend(loc='upper center',  bbox_to_anchor=(0.5, -0.12), shadow=True, ncol=2)\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#66c2a5','#fc8d62','#8da0cb','#e78ac3']\n",
    "markers = [\"s\", \"*\", \"x\", \"D\"]\n",
    "dff = read_grouped(\"backup/imagenet.json\")\n",
    "\n",
    "# Generate individual plots the usage of the big model for each batch and method. These plot the raw data and are not used in the paper directly.\n",
    "for rejector in dff[\"rejector\"].dropna().unique():\n",
    "    plt.xlabel(\"p\")\n",
    "    plt.ylabel(\"\\widehat p per batch\")\n",
    "    plt.title(f\"Distribution of used budger per batch\")\n",
    "    plot_distribution(dff, plt.gca(), dff[\"calibration\"].dropna().unique(), dff[\"train_method\"].dropna().unique(), markers, colors)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, sharex=True)\n",
    "colors = ['#66c2a5','#fc8d62','#8da0cb','#e78ac3']\n",
    "markers = [\"s\", \"*\", \"x\", \"D\"]\n",
    "\n",
    "# Generate the 3x2 plots of CIFAR100 and Imagenet. This is Fig. 2 in the paper\n",
    "for i,jpath in enumerate([\"cifar100.json\", \"imagenet.json\"]):\n",
    "    df,_ = read_json(jpath)\n",
    "    df_distribution = read_grouped(jpath)\n",
    "\n",
    "    legend_labels = plot_key(df, \"accuracy\", markers, colors, axs[0,i], show_legend = i == 0, x_scale=10)\n",
    "    plot_key(df, \"power\", markers, colors, axs[1,i], show_legend = False, x_scale=10)\n",
    "    # plot_key(df, \"p_per_batch\", markers, colors, axs[2,i], show_legend = False)\n",
    "    plot_distribution(df_distribution, axs[2,i], df[\"calibration\"].dropna().unique(), df[\"train_method\"].dropna().unique(), markers, colors)\n",
    "\n",
    "    if i == 0:\n",
    "        axs[0,i].set_ylabel(\"Test accuracy [\\%]\")\n",
    "        axs[0,i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "        axs[1,i].set_ylabel(\"Power [W]\")\n",
    "        axs[1,i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "        axs[2,i].set_ylabel(r\"$\\widehat p$ per batch [\\%]\")\n",
    "        axs[2,i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "\n",
    "\n",
    "# Set titles for each column\n",
    "axs[0, 0].set_title('CIFAR100')\n",
    "axs[0, 1].set_title('ImageNet')\n",
    "\n",
    "# Add a legend to the figure\n",
    "fig.legend(loc='upper center',  bbox_to_anchor=(0.5, 0), shadow=True, ncol=2)\n",
    "\n",
    "# Adjust the layout to make space for the legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Save the figure to a PDF\n",
    "with PdfPages('cifar100_imagenet.pdf') as pdf:\n",
    "    pdf.savefig(fig, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, sharex=True)\n",
    "colors = ['#66c2a5','#fc8d62','#8da0cb','#e78ac3']\n",
    "markers = [\"s\", \"*\", \"x\", \"D\"]\n",
    "all_files = [os.path.join(\"dt3\", f) for f in os.listdir(\"dt3\") if os.path.join(\"dt3\", f) and f.endswith(\".json\") ]\n",
    "\n",
    "# Generate the 3x2 plots for the UCI datasets. This is Fig. 3 in the paper\n",
    "for i,jpath in enumerate(all_files):\n",
    "    df,_ = read_json(jpath)\n",
    "    df_distribution = read_grouped(jpath)\n",
    "\n",
    "    if i < 3:\n",
    "        legend_labels = plot_key(df, \"accuracy\", markers, colors, axs[i,0], show_legend = i == 0)\n",
    "        axs[i, 0].set_title(jpath.split(\"dt3/\")[1].split(\".json\")[0])\n",
    "    else:\n",
    "        legend_labels = plot_key(df, \"accuracy\", markers, colors, axs[i % 3,1], show_legend = i == 0)\n",
    "        axs[i % 3, 1].set_title(jpath.split(\"dt3/\")[1].split(\".json\")[0])\n",
    "\n",
    "    if i == 0:\n",
    "        axs[0,i].set_ylabel(\"Test accuracy [\\%]\")\n",
    "        axs[0,i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "        axs[1,i].set_ylabel(\"Test accuracy [\\%]\")\n",
    "        axs[1,i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "        axs[2,i].set_ylabel(\"Test accuracy [\\%]\")\n",
    "        axs[2,i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "\n",
    "# Add a legend to the figure\n",
    "fig.legend(loc='upper center',  bbox_to_anchor=(0.5, 0), shadow=True, ncol=2)\n",
    "\n",
    "# Adjust the layout to make space for the legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Save the figure to a PDF\n",
    "with PdfPages('dt3.pdf') as pdf:\n",
    "    pdf.savefig(fig, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "colors = ['#66c2a5','#fc8d62','#8da0cb','#e78ac3']\n",
    "markers = [\"s\", \"*\", \"x\", \"D\"]\n",
    "\n",
    "# Generate the 3x2 plots for each UCI dataset individually. Also generate plots for the ablation study using Random Forest. These plots can be found in the appendix.\n",
    "for base in [\"rf\", \"dt3\"]:\n",
    "    all_files = [os.path.join(base, f) for f in os.listdir(os.path.join(base)) if f.endswith(\".json\") ]\n",
    "\n",
    "    for j in range(0, len(all_files), 2):\n",
    "        fig, axs = plt.subplots(3, 2, sharex=True)\n",
    "        \n",
    "        files = all_files[j:j+2]\n",
    "        for i,jpath in enumerate(files):\n",
    "            df,_ = read_json(jpath)\n",
    "            df_distribution = read_grouped(jpath)\n",
    "\n",
    "            legend_labels = plot_key(df, \"accuracy\", markers, colors, axs[0,i], show_legend = i == 0, x_scale=10)\n",
    "            plot_key(df, \"power\", markers, colors, axs[1,i], show_legend = False, x_scale=10)\n",
    "            # plot_key(df, \"p_per_batch\", markers, colors, axs[2,i], show_legend = False)\n",
    "            plot_distribution(df_distribution, axs[2,i], df[\"calibration\"].dropna().unique(), df[\"train_method\"].dropna().unique(), markers, colors)\n",
    "\n",
    "            if i == 0:\n",
    "                axs[0,i].set_ylabel(\"Test accuracy [\\%]\")\n",
    "                axs[0,i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "                axs[1,i].set_ylabel(\"Power [W]\")\n",
    "                axs[1,i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "                axs[2,i].set_ylabel(r\"$\\widehat p$ per batch [\\%]\")\n",
    "                axs[2,i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "\n",
    "\n",
    "        # Set titles for each column\n",
    "        axs[0, 0].set_title(os.path.basename(files[0]).split(\".\")[0])\n",
    "        axs[0, 1].set_title(os.path.basename(files[1]).split(\".\")[0])\n",
    "\n",
    "        # Add a legend to the figure\n",
    "        fig.legend(loc='upper center',  bbox_to_anchor=(0.5, 0), shadow=True, ncol=2)\n",
    "\n",
    "        # Adjust the layout to make space for the legend\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "        # Save the figure to a PDF\n",
    "        with PdfPages(f'block{j}_{base}.pdf') as pdf:\n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rewoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
